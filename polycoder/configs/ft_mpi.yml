{
  "finetune-data-path": "/lm_data/dataset/dataset_saved/",
  "pad-data-keys": ["input_ids"], #, "mpi_completion"],
  "tokenizer-type": "GPT2BPETokenizer",
  "vocab-file": "data/gpt2-vocab.json",
  "merge-file": "data/gpt2-merges.txt",
  "save": "checkpoints/downstream_tasks/mpi/origLarge_lr6e-4_b4_s10k",
  "load": "checkpoints/checkpoints-2-7B/",
  "finetune": True,
  "split": "100,0,0",
  
  "checkpoint_validation_with_forward_pass": False,

  "tensorboard-dir": "tensorboard",
  "log-dir": "logs",
  "use_wandb": False,
}
