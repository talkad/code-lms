{
  "finetune-data-path": "/lm_data/source/",  #dataset/dataset_saved/",
  "pad-data-keys": ["input_ids"], #, "mpi_completion"],
  "tokenizer-type": "GPT2BPETokenizer",
  "vocab-file": "data/gpt2-vocab.json",
  "merge-file": "data/gpt2-merges.txt",
  "save": "checkpoints/downstream_tasks/omp_bpeLarge_lr16e-5_b4",
    #"checkpoints/downstream_tasks/mpi/bpeLarge_lr6e-4_b4/endtoken/",
  "load": "checkpoints/allc_gpt2tok_2-7B/",
  "finetune": True,
  "split": "100,0,0",
  
  "checkpoint_validation_with_forward_pass": False,

  "tensorboard-dir": "tensorboard",
  "log-dir": "logs",
  "use_wandb": False,
}
