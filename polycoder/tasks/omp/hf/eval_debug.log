[2023-12-05 18:10:22,259 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 18:10:22,259 | compcoder_eval.py | line 76] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 18:11:46,956 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 18:11:46,956 | compcoder_eval.py | line 76] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 18:11:48,824 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 18:11:48,830 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 18:11:49,515 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 18:11:49,518 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 18:11:49,523 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 18:11:49,596 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 18:11:49,599 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 18:15:52,179 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 18:15:52,179 | compcoder_eval.py | line 76] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 18:15:54,015 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 18:15:54,021 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 18:15:54,661 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 18:15:54,664 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 18:15:54,669 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 18:15:54,740 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 18:15:54,743 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 18:18:07,194 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 18:18:07,194 | compcoder_eval.py | line 76] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 18:18:09,103 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 18:18:09,108 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 18:18:09,748 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 18:18:09,750 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 18:18:09,755 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 18:18:09,826 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 18:18:09,829 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 18:21:26,640 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 18:21:26,640 | compcoder_eval.py | line 84] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 18:21:28,535 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 18:21:28,541 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 18:21:29,181 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 18:21:29,183 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 18:21:29,189 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 18:21:29,260 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 18:21:29,262 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 18:23:26,236 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 18:23:26,237 | compcoder_eval.py | line 79] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 18:23:28,200 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 18:23:28,206 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 18:23:28,845 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 18:23:28,848 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 18:23:28,854 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 18:23:28,925 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 18:23:28,928 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 18:25:08,835 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 18:25:08,835 | compcoder_eval.py | line 79] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 18:25:10,739 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 18:25:10,745 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 18:25:11,386 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 18:25:11,388 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 18:25:11,394 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 18:25:11,465 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 18:25:11,467 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 18:27:22,128 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 18:27:22,128 | compcoder_eval.py | line 79] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 18:27:23,974 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 18:27:23,979 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 18:27:24,619 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 18:27:24,622 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 18:27:24,627 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 18:27:24,698 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 18:27:24,700 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 18:34:16,452 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 18:34:16,452 | compcoder_eval.py | line 79] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 18:34:18,359 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 18:34:18,364 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 18:34:19,003 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 18:34:19,006 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 18:34:19,011 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 18:34:19,082 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 18:34:19,085 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 18:36:15,193 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 18:36:15,193 | compcoder_eval.py | line 79] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 18:36:17,062 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 18:36:17,068 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 18:36:17,708 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 18:36:17,710 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 18:36:17,716 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 18:36:17,786 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 18:36:17,789 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 18:38:32,063 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 18:38:32,063 | compcoder_eval.py | line 79] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 18:38:33,904 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 18:38:33,910 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 18:38:34,548 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 18:38:34,551 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 18:38:34,556 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 18:38:34,627 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 18:38:34,629 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 18:45:21,114 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 18:45:21,114 | compcoder_eval.py | line 79] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 18:45:22,963 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 18:45:22,969 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 18:45:23,609 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 18:45:23,612 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 18:45:23,617 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 18:45:23,688 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 18:45:23,691 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 18:47:08,110 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 18:47:08,114 | compcoder_eval.py | line 79] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 18:47:10,033 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 18:47:10,038 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 18:47:10,680 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 18:47:10,683 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 18:47:10,689 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 18:47:10,759 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 18:47:10,762 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 18:49:20,843 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 18:49:20,844 | compcoder_eval.py | line 79] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 18:49:22,706 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 18:49:22,712 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 18:49:23,352 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 18:49:23,355 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 18:49:23,360 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 18:49:23,431 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 18:49:23,434 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 18:50:52,094 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 18:50:52,094 | compcoder_eval.py | line 79] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 18:50:53,979 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 18:50:53,985 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 18:50:54,627 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 18:50:54,630 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 18:50:54,635 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 18:50:54,706 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 18:50:54,709 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 18:54:43,430 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 18:54:43,431 | compcoder_eval.py | line 79] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 18:54:45,265 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 18:54:45,271 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 18:54:45,910 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 18:54:45,913 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 18:54:45,918 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 18:54:45,989 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 18:54:45,992 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 18:59:01,985 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 18:59:01,985 | compcoder_eval.py | line 79] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 18:59:03,854 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 18:59:03,860 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 18:59:04,500 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 18:59:04,502 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 18:59:04,508 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 18:59:04,578 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 18:59:04,581 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 19:01:34,809 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 19:01:34,810 | compcoder_eval.py | line 79] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 19:01:36,639 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 19:01:36,645 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 19:01:37,284 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 19:01:37,286 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 19:01:37,291 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 19:01:37,362 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 19:01:37,365 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 19:04:11,040 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 19:04:11,040 | compcoder_eval.py | line 79] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 19:04:12,927 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 19:04:12,933 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 19:04:13,572 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 19:04:13,575 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 19:04:13,580 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 19:04:13,651 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 19:04:13,654 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 19:08:47,467 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 19:08:47,467 | compcoder_eval.py | line 79] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 19:08:49,356 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 19:08:49,362 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 19:08:50,002 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 19:08:50,004 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 19:08:50,010 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 19:08:50,081 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 19:08:50,083 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-06 16:24:11,915 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+------------------------------------------------------------------------------------------------+
| Configuration                | Value                                                                                          |
+------------------------------+------------------------------------------------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints                                                      |
| model_name                   | allc_gpt2tok_700M                                                                              |
| do_finetune                  | False                                                                                          |
| do_eval                      | True                                                                                           |
| do_test                      | False                                                                                          |
| device                       | cuda                                                                                           |
| logger                       | eval_debug.log                                                                                 |
| tokenizer_type               | GPT2BPETokenizer                                                                               |
| vocab_file                   | /mnt/lbosm1/home/Share/code-lms/polycoder/tasks/tokenizer/tokompiler/tokenizer_vocab/vocab.txt |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt                                          |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset                                                       |
| data_device                  | cpu                                                                                            |
| is_replaced                  | False                                                                                          |
| data_filename                | cpu_openmp_unique.jsonl                                                                        |
| save                         | True                                                                                           |
| rank                         | 0                                                                                              |
| make_vocab_size_divisible_by | 128                                                                                            |
| model_parallel_size          | 1                                                                                              |
| save_dir                     | outputs                                                                                        |
| batch_size                   | 1                                                                                              |
| lr                           | 0.00016                                                                                        |
| warmup_steps                 | 400                                                                                            |
| weight_decay                 | 0                                                                                              |
| training_steps               | 100                                                                                            |
| num_epochs                   | 1                                                                                              |
| adam_beta1                   | 0.9                                                                                            |
| adam_beta2                   | 0.999                                                                                          |
| adam_eps                     | 1e-08                                                                                          |
| freeze                       | False                                                                                          |
+------------------------------+------------------------------------------------------------------------------------------------+
[2023-12-06 16:24:11,915 | compcoder_eval.py | line 81] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-06 16:27:47,480 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+------------------------------------------------------------------------------------------------+
| Configuration                | Value                                                                                          |
+------------------------------+------------------------------------------------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints                                                      |
| model_name                   | allc_gpt2tok_700M                                                                              |
| do_finetune                  | False                                                                                          |
| do_eval                      | True                                                                                           |
| do_test                      | False                                                                                          |
| device                       | cuda                                                                                           |
| logger                       | eval_debug.log                                                                                 |
| tokenizer_type               | GPT2BPETokenizer                                                                               |
| vocab_file                   | /mnt/lbosm1/home/Share/code-lms/polycoder/tasks/tokenizer/tokompiler/tokenizer_vocab/vocab.txt |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt                                          |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset                                                       |
| data_device                  | cpu                                                                                            |
| is_replaced                  | False                                                                                          |
| data_filename                | cpu_openmp_unique.jsonl                                                                        |
| save                         | True                                                                                           |
| rank                         | 0                                                                                              |
| make_vocab_size_divisible_by | 128                                                                                            |
| model_parallel_size          | 1                                                                                              |
| save_dir                     | outputs                                                                                        |
| batch_size                   | 1                                                                                              |
| lr                           | 0.00016                                                                                        |
| warmup_steps                 | 400                                                                                            |
| weight_decay                 | 0                                                                                              |
| training_steps               | 100                                                                                            |
| num_epochs                   | 1                                                                                              |
| adam_beta1                   | 0.9                                                                                            |
| adam_beta2                   | 0.999                                                                                          |
| adam_eps                     | 1e-08                                                                                          |
| freeze                       | False                                                                                          |
+------------------------------+------------------------------------------------------------------------------------------------+
[2023-12-06 16:27:47,480 | compcoder_eval.py | line 81] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-06 16:28:32,845 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+------------------------------------------------------------------------------------------------+
| Configuration                | Value                                                                                          |
+------------------------------+------------------------------------------------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints                                                      |
| model_name                   | allc_gpt2tok_700M                                                                              |
| do_finetune                  | False                                                                                          |
| do_eval                      | True                                                                                           |
| do_test                      | False                                                                                          |
| device                       | cuda                                                                                           |
| logger                       | eval_debug.log                                                                                 |
| tokenizer_type               | GPT2BPETokenizer                                                                               |
| vocab_file                   | /mnt/lbosm1/home/Share/code-lms/polycoder/tasks/tokenizer/tokompiler/tokenizer_vocab/vocab.txt |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt                                          |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset                                                       |
| data_device                  | cpu                                                                                            |
| is_replaced                  | False                                                                                          |
| data_filename                | cpu_openmp_unique.jsonl                                                                        |
| save                         | True                                                                                           |
| rank                         | 0                                                                                              |
| make_vocab_size_divisible_by | 128                                                                                            |
| model_parallel_size          | 1                                                                                              |
| save_dir                     | outputs                                                                                        |
| batch_size                   | 1                                                                                              |
| lr                           | 0.00016                                                                                        |
| warmup_steps                 | 400                                                                                            |
| weight_decay                 | 0                                                                                              |
| training_steps               | 100                                                                                            |
| num_epochs                   | 1                                                                                              |
| adam_beta1                   | 0.9                                                                                            |
| adam_beta2                   | 0.999                                                                                          |
| adam_eps                     | 1e-08                                                                                          |
| freeze                       | False                                                                                          |
+------------------------------+------------------------------------------------------------------------------------------------+
[2023-12-06 16:28:32,845 | compcoder_eval.py | line 81] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-06 16:30:28,686 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+------------------------------------------------------------------------------------------------+
| Configuration                | Value                                                                                          |
+------------------------------+------------------------------------------------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints                                                      |
| model_name                   | allc_gpt2tok_700M                                                                              |
| do_finetune                  | False                                                                                          |
| do_eval                      | True                                                                                           |
| do_test                      | False                                                                                          |
| device                       | cuda                                                                                           |
| logger                       | eval_debug.log                                                                                 |
| tokenizer_type               | GPT2BPETokenizer                                                                               |
| vocab_file                   | /mnt/lbosm1/home/Share/code-lms/polycoder/tasks/tokenizer/tokompiler/tokenizer_vocab/vocab.txt |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt                                          |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset                                                       |
| data_device                  | cpu                                                                                            |
| is_replaced                  | False                                                                                          |
| data_filename                | cpu_openmp_unique.jsonl                                                                        |
| save                         | True                                                                                           |
| rank                         | 0                                                                                              |
| make_vocab_size_divisible_by | 128                                                                                            |
| model_parallel_size          | 1                                                                                              |
| save_dir                     | outputs                                                                                        |
| batch_size                   | 1                                                                                              |
| lr                           | 0.00016                                                                                        |
| warmup_steps                 | 400                                                                                            |
| weight_decay                 | 0                                                                                              |
| training_steps               | 100                                                                                            |
| num_epochs                   | 1                                                                                              |
| adam_beta1                   | 0.9                                                                                            |
| adam_beta2                   | 0.999                                                                                          |
| adam_eps                     | 1e-08                                                                                          |
| freeze                       | False                                                                                          |
+------------------------------+------------------------------------------------------------------------------------------------+
[2023-12-06 16:30:28,686 | compcoder_eval.py | line 81] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-06 16:32:31,863 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+------------------------------------------------------------------------------------------------+
| Configuration                | Value                                                                                          |
+------------------------------+------------------------------------------------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints                                                      |
| model_name                   | allc_gpt2tok_700M                                                                              |
| do_finetune                  | False                                                                                          |
| do_eval                      | True                                                                                           |
| do_test                      | False                                                                                          |
| device                       | cuda                                                                                           |
| logger                       | eval_debug.log                                                                                 |
| tokenizer_type               | GPT2BPETokenizer                                                                               |
| vocab_file                   | /mnt/lbosm1/home/Share/code-lms/polycoder/tasks/tokenizer/tokompiler/tokenizer_vocab/vocab.txt |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt                                          |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset                                                       |
| data_device                  | cpu                                                                                            |
| is_replaced                  | False                                                                                          |
| data_filename                | cpu_openmp_unique.jsonl                                                                        |
| save                         | True                                                                                           |
| rank                         | 0                                                                                              |
| make_vocab_size_divisible_by | 128                                                                                            |
| model_parallel_size          | 1                                                                                              |
| save_dir                     | outputs                                                                                        |
| batch_size                   | 1                                                                                              |
| lr                           | 0.00016                                                                                        |
| warmup_steps                 | 400                                                                                            |
| weight_decay                 | 0                                                                                              |
| training_steps               | 100                                                                                            |
| num_epochs                   | 1                                                                                              |
| adam_beta1                   | 0.9                                                                                            |
| adam_beta2                   | 0.999                                                                                          |
| adam_eps                     | 1e-08                                                                                          |
| freeze                       | False                                                                                          |
+------------------------------+------------------------------------------------------------------------------------------------+
[2023-12-06 16:32:31,863 | compcoder_eval.py | line 81] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-06 16:34:56,823 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+------------------------------------------------------------------------------------------------+
| Configuration                | Value                                                                                          |
+------------------------------+------------------------------------------------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints                                                      |
| model_name                   | allc_gpt2tok_700M                                                                              |
| do_finetune                  | False                                                                                          |
| do_eval                      | True                                                                                           |
| do_test                      | False                                                                                          |
| device                       | cuda                                                                                           |
| logger                       | eval_debug.log                                                                                 |
| tokenizer_type               | GPT2BPETokenizer                                                                               |
| vocab_file                   | /mnt/lbosm1/home/Share/code-lms/polycoder/tasks/tokenizer/tokompiler/tokenizer_vocab/vocab.txt |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt                                          |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset                                                       |
| data_device                  | cpu                                                                                            |
| is_replaced                  | False                                                                                          |
| data_filename                | cpu_openmp_unique.jsonl                                                                        |
| save                         | True                                                                                           |
| rank                         | 0                                                                                              |
| make_vocab_size_divisible_by | 128                                                                                            |
| model_parallel_size          | 1                                                                                              |
| save_dir                     | outputs                                                                                        |
| batch_size                   | 1                                                                                              |
| lr                           | 0.00016                                                                                        |
| warmup_steps                 | 400                                                                                            |
| weight_decay                 | 0                                                                                              |
| training_steps               | 100                                                                                            |
| num_epochs                   | 1                                                                                              |
| adam_beta1                   | 0.9                                                                                            |
| adam_beta2                   | 0.999                                                                                          |
| adam_eps                     | 1e-08                                                                                          |
| freeze                       | False                                                                                          |
+------------------------------+------------------------------------------------------------------------------------------------+
[2023-12-06 16:34:56,823 | compcoder_eval.py | line 81] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-06 16:47:02,145 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-06 16:47:02,145 | compcoder_eval.py | line 81] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-06 16:47:04,002 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-06 16:47:04,008 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-06 16:47:04,654 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-06 16:47:04,656 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-06 16:47:04,661 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-06 16:47:04,733 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-06 16:47:04,736 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-06 16:50:35,027 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-06 16:50:35,028 | compcoder_eval.py | line 81] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-06 16:50:36,868 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-06 16:50:36,874 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-06 16:50:37,513 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-06 16:50:37,516 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-06 16:50:37,521 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-06 16:50:37,592 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-06 16:50:37,595 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-07 10:55:32,336 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-07 10:55:32,336 | compcoder_eval.py | line 81] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-07 10:55:34,199 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-07 10:55:34,205 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-07 10:55:34,845 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-07 10:55:34,847 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-07 10:55:34,853 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-07 10:55:34,924 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-07 10:55:34,926 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-07 11:26:34,446 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-07 11:26:34,447 | compcoder_eval.py | line 81] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-07 11:26:36,365 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-07 11:26:36,371 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-07 11:26:37,009 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-07 11:26:37,012 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-07 11:26:37,017 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-07 11:26:37,088 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-07 11:26:37,090 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-07 11:33:09,739 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-07 11:33:09,739 | compcoder_eval.py | line 81] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-07 11:33:11,643 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-07 11:33:11,649 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-07 11:33:12,288 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-07 11:33:12,290 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-07 11:33:12,296 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-07 11:33:12,366 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-07 11:33:12,369 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-07 15:16:31,334 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-07 15:16:31,334 | compcoder_eval.py | line 90] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-07 15:17:00,923 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-07 15:17:00,924 | compcoder_eval.py | line 90] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-07 15:17:01,432 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-07 15:17:01,439 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-07 15:17:01,746 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-07 15:17:01,749 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-07 15:17:01,754 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-07 15:17:02,061 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-07 15:17:02,063 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
[2023-12-07 15:17:47,127 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-07 15:17:47,128 | compcoder_eval.py | line 90] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-07 15:17:47,635 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-07 15:17:47,640 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-07 15:17:47,950 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-07 15:17:47,953 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-07 15:17:47,957 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-07 15:17:48,267 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-07 15:17:48,270 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
[2023-12-07 15:25:48,472 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-07 15:25:48,472 | compcoder_eval.py | line 90] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-07 15:25:48,985 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-07 15:25:48,990 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-07 15:25:49,300 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-07 15:25:49,302 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-07 15:25:49,306 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-07 15:25:49,616 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-07 15:25:49,620 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
[2023-12-07 15:27:12,826 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-07 15:27:12,827 | compcoder_eval.py | line 90] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-07 15:27:13,332 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-07 15:27:13,336 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-07 15:27:13,647 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-07 15:27:13,649 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-07 15:27:13,653 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-07 15:27:13,963 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-07 15:27:13,966 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
[2023-12-07 15:34:34,636 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-07 15:34:34,637 | compcoder_eval.py | line 90] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-07 15:34:35,143 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-07 15:34:35,147 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-07 15:34:35,457 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-07 15:34:35,460 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-07 15:34:35,464 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-07 15:34:35,773 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-07 15:34:35,777 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
[2023-12-07 15:36:19,086 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-07 15:36:19,086 | compcoder_eval.py | line 90] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-07 15:36:19,597 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-07 15:36:19,602 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-07 15:36:19,912 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-07 15:36:19,915 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-07 15:36:19,919 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-07 15:36:20,229 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-07 15:36:20,232 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
[2023-12-07 15:38:43,296 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-07 15:38:43,297 | compcoder_eval.py | line 90] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-07 15:38:43,800 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-07 15:38:43,805 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-07 15:38:44,115 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-07 15:38:44,119 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-07 15:38:44,123 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-07 15:38:44,433 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-07 15:38:44,436 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
[2023-12-07 15:40:38,443 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-07 15:40:38,443 | compcoder_eval.py | line 90] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-07 15:40:38,952 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-07 15:40:38,957 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-07 15:40:39,267 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-07 15:40:39,269 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-07 15:40:39,274 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-07 15:40:39,584 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-07 15:40:39,587 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
[2023-12-07 15:42:46,598 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-07 15:42:46,598 | compcoder_eval.py | line 90] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-07 15:42:47,108 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-07 15:42:47,113 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-07 15:42:47,423 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-07 15:42:47,425 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-07 15:42:47,430 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-07 15:42:47,739 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-07 15:42:47,743 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
[2023-12-07 15:45:18,451 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-07 15:45:18,451 | compcoder_eval.py | line 91] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-07 15:45:18,962 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-07 15:45:18,967 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-07 15:45:19,277 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-07 15:45:19,281 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-07 15:45:19,285 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-07 15:45:19,595 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-07 15:45:19,597 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
[2023-12-07 16:08:26,811 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-07 16:08:26,811 | compcoder_eval.py | line 92] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-07 16:08:27,325 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-07 16:08:27,330 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-07 16:08:27,640 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-07 16:08:27,643 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-07 16:08:27,648 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-07 16:08:27,958 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-07 16:08:27,960 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
[2023-12-07 16:08:46,073 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-07 16:08:46,074 | compcoder_eval.py | line 92] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-07 16:08:46,575 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-07 16:08:46,580 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-07 16:08:46,890 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-07 16:08:46,893 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-07 16:08:46,897 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-07 16:08:47,207 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-07 16:08:47,210 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
[2023-12-07 16:16:43,744 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-07 16:16:43,744 | compcoder_eval.py | line 92] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-07 16:16:44,248 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-07 16:16:44,253 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-07 16:16:44,563 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-07 16:16:44,565 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-07 16:16:44,570 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-07 16:16:44,880 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-07 16:16:44,883 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
[2023-12-07 16:17:31,128 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-07 16:17:31,128 | compcoder_eval.py | line 92] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-07 16:17:31,635 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-07 16:17:31,640 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-07 16:17:31,950 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-07 16:17:31,953 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-07 16:17:31,957 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-07 16:17:32,267 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-07 16:17:32,270 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
[2023-12-07 16:24:25,150 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-07 16:24:25,150 | compcoder_eval.py | line 92] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-07 16:24:25,483 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-07 16:24:25,487 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-07 16:24:25,556 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-07 16:24:25,558 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-07 16:24:25,562 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-07 16:24:25,630 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-07 16:24:25,632 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
[2023-12-07 17:26:49,979 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-07 17:26:49,980 | compcoder_eval.py | line 92] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-07 17:26:50,312 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-07 17:26:50,317 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-07 17:26:50,383 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-07 17:26:50,385 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-07 17:26:50,390 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-07 17:26:50,455 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-07 17:26:50,458 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
[2023-12-07 17:36:24,117 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-07 17:36:24,117 | compcoder_eval.py | line 92] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-07 17:36:24,445 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-07 17:36:24,450 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-07 17:36:24,516 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-07 17:36:24,518 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-07 17:36:24,523 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-07 17:36:24,588 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-07 17:36:24,591 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
[2023-12-07 18:04:23,169 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-07 18:04:23,169 | compcoder_eval.py | line 92] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-07 18:04:24,035 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-07 18:04:24,043 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-07 18:04:24,112 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-07 18:04:24,116 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-07 18:04:24,125 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-07 18:04:24,195 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-07 18:04:24,199 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
[2023-12-07 20:52:59,429 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-07 20:52:59,429 | compcoder_eval.py | line 92] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-07 20:53:00,093 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-07 20:53:00,097 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-07 20:53:00,175 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-07 20:53:00,178 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-07 20:53:00,182 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-07 20:53:00,259 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-07 20:53:00,262 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
[2023-12-07 21:10:55,355 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-07 21:10:55,355 | compcoder_eval.py | line 92] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-07 21:10:56,019 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-07 21:10:56,024 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-07 21:10:56,102 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-07 21:10:56,104 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-07 21:10:56,108 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-07 21:10:56,186 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-07 21:10:56,188 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
[2023-12-07 21:12:40,280 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-07 21:12:40,281 | compcoder_eval.py | line 92] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-07 21:12:40,996 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-07 21:12:41,002 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-07 21:12:41,082 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-07 21:12:41,086 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-07 21:12:41,095 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-07 21:12:41,176 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-07 21:12:41,180 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
[2023-12-07 21:14:48,324 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-07 21:14:48,324 | compcoder_eval.py | line 92] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-07 21:14:48,674 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-07 21:14:48,679 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-07 21:14:48,757 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-07 21:14:48,760 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-07 21:14:48,764 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-07 21:14:48,842 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-07 21:14:48,844 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
[2023-12-07 22:49:10,957 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-07 22:49:10,958 | compcoder_eval.py | line 92] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-07 22:49:58,228 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-07 22:49:58,229 | compcoder_eval.py | line 93] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-07 22:49:58,238 | connectionpool.py | line 1052] - DEBUG: Starting new HTTPS connection (1): huggingface.co:443
[2023-12-07 22:49:58,995 | connectionpool.py | line 546] - DEBUG: https://huggingface.co:443 "HEAD /NinedayWang/PolyCoder-2.7B/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[2023-12-07 22:49:59,547 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-07 22:49:59,554 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-07 22:49:59,623 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-07 22:49:59,627 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-07 22:49:59,635 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-07 22:49:59,705 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-07 22:49:59,710 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
[2023-12-07 22:50:02,813 | connectionpool.py | line 546] - DEBUG: https://huggingface.co:443 "HEAD /NinedayWang/PolyCoder-2.7B/resolve/main/config.json HTTP/1.1" 200 0
[2023-12-07 22:57:00,510 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-07 22:57:00,510 | compcoder_eval.py | line 93] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-07 22:57:00,518 | connectionpool.py | line 1052] - DEBUG: Starting new HTTPS connection (1): huggingface.co:443
[2023-12-07 22:57:00,753 | connectionpool.py | line 546] - DEBUG: https://huggingface.co:443 "HEAD /NinedayWang/PolyCoder-2.7B/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[2023-12-07 22:57:01,164 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-07 22:57:01,169 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-07 22:57:01,235 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-07 22:57:01,238 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-07 22:57:01,242 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-07 22:57:01,308 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-07 22:57:01,310 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
[2023-12-07 22:57:04,853 | connectionpool.py | line 546] - DEBUG: https://huggingface.co:443 "HEAD /NinedayWang/PolyCoder-2.7B/resolve/main/config.json HTTP/1.1" 200 0
[2023-12-07 23:01:32,627 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-07 23:01:32,627 | compcoder_eval.py | line 93] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-07 23:01:32,656 | connectionpool.py | line 1052] - DEBUG: Starting new HTTPS connection (1): huggingface.co:443
[2023-12-07 23:01:33,079 | connectionpool.py | line 546] - DEBUG: https://huggingface.co:443 "HEAD /NinedayWang/PolyCoder-2.7B/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[2023-12-07 23:01:33,829 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-07 23:01:33,864 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-07 23:01:33,952 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-07 23:01:33,976 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-07 23:01:34,002 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-07 23:01:34,089 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-07 23:01:34,113 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
[2023-12-07 23:01:37,558 | connectionpool.py | line 546] - DEBUG: https://huggingface.co:443 "HEAD /NinedayWang/PolyCoder-2.7B/resolve/main/config.json HTTP/1.1" 200 0
[2023-12-08 10:29:47,054 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-08 10:29:47,054 | compcoder_eval.py | line 98] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-08 10:29:47,059 | connectionpool.py | line 1052] - DEBUG: Starting new HTTPS connection (1): huggingface.co:443
[2023-12-08 10:29:47,753 | connectionpool.py | line 546] - DEBUG: https://huggingface.co:443 "HEAD /NinedayWang/PolyCoder-2.7B/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[2023-12-08 10:29:48,179 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-08 10:29:48,183 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-08 10:29:48,261 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-08 10:29:48,263 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-08 10:29:48,267 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-08 10:29:48,345 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-08 10:29:48,348 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
[2023-12-08 10:31:11,092 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_debug.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | False                                                 |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-08 10:31:11,092 | compcoder_eval.py | line 98] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-08 10:31:11,102 | connectionpool.py | line 1052] - DEBUG: Starting new HTTPS connection (1): huggingface.co:443
[2023-12-08 10:31:11,294 | connectionpool.py | line 546] - DEBUG: https://huggingface.co:443 "HEAD /NinedayWang/PolyCoder-2.7B/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[2023-12-08 10:31:11,697 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-08 10:31:11,701 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-08 10:31:11,780 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-08 10:31:11,783 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-08 10:31:11,787 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-08 10:31:11,865 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-08 10:31:11,868 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
