[2023-12-05 19:12:04,033 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 19:12:04,033 | compcoder_eval.py | line 79] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 19:12:41,031 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 19:12:41,037 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 19:12:42,239 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 19:12:42,244 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 19:12:42,249 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 19:12:42,386 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 19:12:42,388 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 19:15:34,173 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 19:15:34,173 | compcoder_eval.py | line 79] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 19:16:11,048 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 19:16:11,054 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 19:16:12,222 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 19:16:12,227 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 19:16:12,232 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 19:16:12,366 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 19:16:12,369 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 19:20:47,841 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 19:20:47,841 | compcoder_eval.py | line 80] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 19:21:24,688 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 19:21:24,694 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 19:21:25,863 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 19:21:25,868 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 19:21:25,874 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 19:21:26,009 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 19:21:26,012 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 19:27:04,614 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 19:27:04,614 | compcoder_eval.py | line 80] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 19:27:41,362 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 19:27:41,368 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 19:27:42,537 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 19:27:42,542 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 19:27:42,547 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 19:27:42,682 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 19:27:42,685 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 19:30:36,103 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 19:30:36,103 | compcoder_eval.py | line 80] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 19:31:12,604 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 19:31:12,611 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 19:31:13,783 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 19:31:13,788 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 19:31:13,793 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 19:31:13,928 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 19:31:13,931 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 19:34:28,480 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 19:34:28,480 | compcoder_eval.py | line 80] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 19:35:05,319 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 19:35:05,325 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 19:35:06,496 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 19:35:06,501 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 19:35:06,506 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 19:35:06,641 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 19:35:06,644 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 19:39:30,416 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 19:39:30,416 | compcoder_eval.py | line 81] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 19:40:07,539 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 19:40:07,545 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 19:40:08,718 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 19:40:08,723 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 19:40:08,728 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 19:40:08,864 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 19:40:08,867 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 19:44:03,899 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 19:44:03,899 | compcoder_eval.py | line 81] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 19:44:40,839 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 19:44:40,845 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 19:44:42,015 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 19:44:42,020 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 19:44:42,025 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 19:44:42,160 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 19:44:42,162 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 19:48:12,520 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 19:48:12,521 | compcoder_eval.py | line 81] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 19:48:49,537 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 19:48:49,543 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 19:48:50,712 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 19:48:50,717 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 19:48:50,722 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 19:48:50,857 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 19:48:50,860 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 19:52:17,956 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 19:52:17,956 | compcoder_eval.py | line 81] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 19:52:55,146 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 19:52:55,152 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 19:52:56,323 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 19:52:56,328 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 19:52:56,334 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 19:52:56,468 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 19:52:56,471 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 19:55:42,483 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 19:55:42,483 | compcoder_eval.py | line 81] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 19:56:19,195 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 19:56:19,202 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 19:56:20,371 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 19:56:20,376 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 19:56:20,381 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 19:56:20,516 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 19:56:20,519 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 19:58:45,451 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 19:58:45,451 | compcoder_eval.py | line 81] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 19:59:22,547 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 19:59:22,553 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 19:59:23,722 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 19:59:23,727 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 19:59:23,733 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 19:59:23,867 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 19:59:23,870 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 20:01:51,221 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 20:01:51,221 | compcoder_eval.py | line 81] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 20:03:25,610 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 20:03:25,610 | compcoder_eval.py | line 81] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 20:04:02,730 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 20:04:02,737 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 20:04:03,906 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 20:04:03,911 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 20:04:03,916 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 20:04:04,050 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 20:04:04,053 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 20:07:11,844 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 20:07:11,845 | compcoder_eval.py | line 81] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 20:07:48,912 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 20:07:48,918 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 20:07:50,087 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 20:07:50,092 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 20:07:50,097 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 20:07:50,232 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 20:07:50,235 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 20:10:56,145 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 20:10:56,146 | compcoder_eval.py | line 81] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 20:11:33,311 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 20:11:33,318 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 20:11:34,489 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 20:11:34,494 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 20:11:34,500 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 20:11:34,635 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 20:11:34,638 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 20:14:42,548 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 20:14:42,548 | compcoder_eval.py | line 81] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 20:15:19,816 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 20:15:19,822 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 20:15:20,991 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 20:15:20,996 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 20:15:21,001 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 20:15:21,136 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 20:15:21,139 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
