[2023-12-05 19:12:04,033 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 19:12:04,033 | compcoder_eval.py | line 79] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 19:12:41,031 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 19:12:41,037 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 19:12:42,239 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 19:12:42,244 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 19:12:42,249 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 19:12:42,386 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 19:12:42,388 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 19:15:34,173 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 19:15:34,173 | compcoder_eval.py | line 79] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 19:16:11,048 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 19:16:11,054 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 19:16:12,222 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 19:16:12,227 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 19:16:12,232 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 19:16:12,366 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 19:16:12,369 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 19:20:47,841 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 19:20:47,841 | compcoder_eval.py | line 80] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 19:21:24,688 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 19:21:24,694 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 19:21:25,863 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 19:21:25,868 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 19:21:25,874 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 19:21:26,009 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 19:21:26,012 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 19:27:04,614 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 19:27:04,614 | compcoder_eval.py | line 80] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 19:27:41,362 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 19:27:41,368 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 19:27:42,537 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 19:27:42,542 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 19:27:42,547 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 19:27:42,682 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 19:27:42,685 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 19:30:36,103 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 19:30:36,103 | compcoder_eval.py | line 80] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 19:31:12,604 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 19:31:12,611 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 19:31:13,783 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 19:31:13,788 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 19:31:13,793 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 19:31:13,928 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 19:31:13,931 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 19:34:28,480 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 19:34:28,480 | compcoder_eval.py | line 80] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 19:35:05,319 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 19:35:05,325 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 19:35:06,496 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 19:35:06,501 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 19:35:06,506 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 19:35:06,641 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 19:35:06,644 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 19:39:30,416 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 19:39:30,416 | compcoder_eval.py | line 81] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 19:40:07,539 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 19:40:07,545 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 19:40:08,718 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 19:40:08,723 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 19:40:08,728 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 19:40:08,864 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 19:40:08,867 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 19:44:03,899 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 19:44:03,899 | compcoder_eval.py | line 81] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 19:44:40,839 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 19:44:40,845 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 19:44:42,015 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 19:44:42,020 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 19:44:42,025 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 19:44:42,160 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 19:44:42,162 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 19:48:12,520 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 19:48:12,521 | compcoder_eval.py | line 81] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 19:48:49,537 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 19:48:49,543 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 19:48:50,712 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 19:48:50,717 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 19:48:50,722 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 19:48:50,857 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 19:48:50,860 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 19:52:17,956 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 19:52:17,956 | compcoder_eval.py | line 81] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 19:52:55,146 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 19:52:55,152 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 19:52:56,323 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 19:52:56,328 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 19:52:56,334 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 19:52:56,468 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 19:52:56,471 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 19:55:42,483 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 19:55:42,483 | compcoder_eval.py | line 81] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 19:56:19,195 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 19:56:19,202 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 19:56:20,371 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 19:56:20,376 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 19:56:20,381 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 19:56:20,516 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 19:56:20,519 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 19:58:45,451 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 19:58:45,451 | compcoder_eval.py | line 81] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 19:59:22,547 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 19:59:22,553 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 19:59:23,722 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 19:59:23,727 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 19:59:23,733 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 19:59:23,867 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 19:59:23,870 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 20:01:51,221 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 20:01:51,221 | compcoder_eval.py | line 81] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 20:03:25,610 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 20:03:25,610 | compcoder_eval.py | line 81] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 20:04:02,730 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 20:04:02,737 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 20:04:03,906 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 20:04:03,911 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 20:04:03,916 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 20:04:04,050 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 20:04:04,053 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 20:07:11,844 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 20:07:11,845 | compcoder_eval.py | line 81] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 20:07:48,912 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 20:07:48,918 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 20:07:50,087 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 20:07:50,092 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 20:07:50,097 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 20:07:50,232 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 20:07:50,235 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 20:10:56,145 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 20:10:56,146 | compcoder_eval.py | line 81] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 20:11:33,311 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 20:11:33,318 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 20:11:34,489 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 20:11:34,494 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 20:11:34,500 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 20:11:34,635 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 20:11:34,638 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-05 20:14:42,548 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-05 20:14:42,548 | compcoder_eval.py | line 81] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-05 20:15:19,816 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-05 20:15:19,822 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-05 20:15:20,991 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-05 20:15:20,996 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-05 20:15:21,001 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-05 20:15:21,136 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-05 20:15:21,139 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-06 16:36:03,892 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-06 16:36:03,892 | compcoder_eval.py | line 81] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-06 16:36:40,428 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-06 16:36:40,434 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-06 16:36:41,602 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-06 16:36:41,607 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-06 16:36:41,612 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-06 16:36:41,747 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-06 16:36:41,749 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-06 16:40:40,856 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE/OMP_Dataset              |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-06 16:40:40,856 | compcoder_eval.py | line 81] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-06 16:41:17,866 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/dataset_dict.json
[2023-12-06 16:41:17,871 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/data-00000-of-00001.arrow
[2023-12-06 16:41:19,040 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/state.json
[2023-12-06 16:41:19,045 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/train/dataset_info.json
[2023-12-06 16:41:19,050 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/data-00000-of-00001.arrow
[2023-12-06 16:41:19,185 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/state.json
[2023-12-06 16:41:19,187 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/OMP_Dataset/test/dataset_info.json
[2023-12-08 09:46:42,601 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-08 09:46:42,601 | compcoder_eval.py | line 93] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-08 09:46:47,398 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-08 09:46:47,403 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-08 09:46:47,478 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-08 09:46:47,480 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-08 09:46:47,485 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-08 09:46:47,560 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-08 09:46:47,563 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
[2023-12-08 09:53:47,622 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-08 09:53:47,623 | compcoder_eval.py | line 93] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-08 09:53:52,393 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-08 09:53:52,398 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-08 09:53:52,473 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-08 09:53:52,475 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-08 09:53:52,480 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-08 09:53:52,555 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-08 09:53:52,558 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
[2023-12-08 09:55:27,427 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-08 09:55:27,428 | compcoder_eval.py | line 93] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-08 09:55:32,223 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-08 09:55:32,227 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-08 09:55:32,303 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-08 09:55:32,305 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-08 09:55:32,310 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-08 09:55:32,385 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-08 09:55:32,388 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
[2023-12-08 09:58:02,173 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-08 09:58:02,174 | compcoder_eval.py | line 93] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-08 09:58:06,986 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-08 09:58:06,991 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-08 09:58:07,067 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-08 09:58:07,069 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-08 09:58:07,074 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-08 09:58:07,149 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-08 09:58:07,151 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
[2023-12-08 10:00:25,514 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-08 10:00:25,515 | compcoder_eval.py | line 93] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-08 10:00:30,323 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-08 10:00:30,327 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-08 10:00:30,403 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-08 10:00:30,405 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-08 10:00:30,410 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-08 10:00:30,485 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-08 10:00:30,488 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
[2023-12-08 10:03:37,603 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-08 10:03:37,603 | compcoder_eval.py | line 93] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-08 10:03:42,390 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-08 10:03:42,395 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-08 10:03:42,470 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-08 10:03:42,473 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-08 10:03:42,477 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-08 10:03:42,553 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-08 10:03:42,555 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
[2023-12-08 10:15:02,267 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-08 10:15:02,267 | compcoder_eval.py | line 98] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-08 10:15:06,993 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-08 10:15:06,998 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-08 10:15:07,074 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-08 10:15:07,076 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-08 10:15:07,081 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-08 10:15:07,156 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-08 10:15:07,158 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
[2023-12-08 10:16:21,944 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-08 10:16:21,944 | compcoder_eval.py | line 98] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-08 10:16:26,738 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-08 10:16:26,743 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-08 10:16:26,818 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-08 10:16:26,821 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-08 10:16:26,825 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-08 10:16:26,900 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-08 10:16:26,903 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
[2023-12-08 10:20:26,930 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-08 10:20:26,931 | compcoder_eval.py | line 98] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-08 10:20:31,685 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-08 10:20:31,690 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-08 10:20:31,765 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-08 10:20:31,768 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-08 10:20:31,772 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-08 10:20:31,847 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-08 10:20:31,850 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
[2023-12-08 10:22:37,738 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-08 10:22:37,738 | compcoder_eval.py | line 98] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-08 10:22:42,475 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-08 10:22:42,480 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-08 10:22:42,556 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-08 10:22:42,558 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-08 10:22:42,563 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-08 10:22:42,638 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-08 10:22:42,640 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
[2023-12-08 10:24:42,138 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-08 10:24:42,139 | compcoder_eval.py | line 98] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-08 10:24:46,890 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-08 10:24:46,895 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-08 10:24:46,970 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-08 10:24:46,972 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-08 10:24:46,977 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-08 10:24:47,052 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-08 10:24:47,055 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
[2023-12-08 10:29:05,667 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-08 10:29:05,668 | compcoder_eval.py | line 98] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-08 10:29:10,464 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-08 10:29:10,469 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-08 10:29:10,544 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-08 10:29:10,547 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-08 10:29:10,551 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-08 10:29:10,627 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-08 10:29:10,629 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
[2023-12-08 10:30:22,079 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-08 10:30:22,080 | compcoder_eval.py | line 98] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-08 10:30:26,463 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-08 10:30:26,469 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-08 10:30:26,548 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-08 10:30:26,552 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-08 10:30:26,561 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-08 10:30:26,641 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-08 10:30:26,644 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
[2023-12-08 13:15:07,669 | main.py | line 87] - DEBUG: Configurations:
+------------------------------+-------------------------------------------------------+
| Configuration                | Value                                                 |
+------------------------------+-------------------------------------------------------+
| models_dir                   | /home/talkad/shared/models/hf_checkpoints             |
| model_name                   | allc_gpt2tok_700M                                     |
| do_finetune                  | False                                                 |
| do_eval                      | True                                                  |
| do_test                      | False                                                 |
| device                       | cuda                                                  |
| logger                       | eval_tokom.log                                        |
| tokenizer_type               | GPT2BPETokenizer                                      |
| vocab_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-vocab.json |
| merge_file                   | ../../../megatron/tokenizer/gpt_vocab/gpt2-merges.txt |
| data_path                    | /home/talkad/LIGHTBITS_SHARE                          |
| data_device                  | cpu                                                   |
| is_replaced                  | True                                                  |
| data_filename                | cpu_openmp_unique.jsonl                               |
| save                         | True                                                  |
| rank                         | 0                                                     |
| make_vocab_size_divisible_by | 128                                                   |
| model_parallel_size          | 1                                                     |
| save_dir                     | outputs                                               |
| batch_size                   | 1                                                     |
| lr                           | 0.00016                                               |
| warmup_steps                 | 400                                                   |
| weight_decay                 | 0                                                     |
| training_steps               | 100                                                   |
| num_epochs                   | 1                                                     |
| adam_beta1                   | 0.9                                                   |
| adam_beta2                   | 0.999                                                 |
| adam_eps                     | 1e-08                                                 |
| freeze                       | False                                                 |
+------------------------------+-------------------------------------------------------+
[2023-12-08 13:15:07,669 | compcoder_eval.py | line 98] - INFO: start compcoder HPC evaluation allc_gpt2tok_700M
[2023-12-08 13:15:12,446 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/dataset_dict.json
[2023-12-08 13:15:12,450 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/data-00000-of-00001.arrow
[2023-12-08 13:15:12,526 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/state.json
[2023-12-08 13:15:12,529 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/train/dataset_info.json
[2023-12-08 13:15:12,533 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/data-00000-of-00001.arrow
[2023-12-08 13:15:12,609 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/state.json
[2023-12-08 13:15:12,611 | local.py | line 294] - DEBUG: open file: /home/talkad/LIGHTBITS_SHARE/test/dataset_info.json
